{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "# embedding_dims = [32, 64, 128, 256, 512, 1024]\n",
    "# hidden_dims = [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]\n",
    "\n",
    "embedding_dims = [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768]\n",
    "margins = [1.,4.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = []\n",
    "\n",
    "for ed, margin in itertools.product(embedding_dims, margins):\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    hyper_path = f\"models/linear_hyper_M{margin_str}_ED{ed}_EP{epochs}.pkl\"\n",
    "\n",
    "    if not os.path.exists(hyper_path):\n",
    "        print(f\" File not found: {hyper_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(hyper_path, 'rb') as f:\n",
    "        saved = pickle.load(f)\n",
    "    \n",
    "    hyper_params.append({\n",
    "        \"model id\": saved[\"model id\"],\n",
    "        \"learning rate\": saved[\"learning rate\"],\n",
    "        \"weight decay\": saved[\"weight decay\"],\n",
    "        \"batch size\": saved[\"batch size\"],\n",
    "        \"embedding dim\": saved[\"embedding dim\"],  \n",
    "        \"l1 lambda\": saved[\"l1 lambda\"],\n",
    "        \"epochs\": saved[\"epochs\"],  \n",
    "        \"margin\": saved[\"margin\"],  \n",
    "        \"patience\": saved[\"patience\"],\n",
    "        \"min delta\": saved[\"min delta\"],\n",
    "        })\n",
    "n_models = len(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdde37",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for hp in hyper_params:  # assuming hyper_params is a list of dicts with 'hidden dim' and 'embedding dim'\n",
    "    margin = hp['margin']\n",
    "    embedding_dim = hp['embedding dim']\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    filename = f\"models/linear_M{margin_str}_ED{embedding_dim}_EP{epochs}.pkl\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\" File not found: {filename}\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        saved_train = pickle.load(f)\n",
    "        \n",
    "    filename = f\"models/linear_test_M{margin_str}_ED{embedding_dim}_EP{epochs}.pkl\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\" File not found: {filename}\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        saved_test = pickle.load(f)\n",
    "\n",
    "    results.append({\n",
    "        \"train_losses\": saved_train[\"train_losses\"],\n",
    "        \"val_losses\": saved_train[\"val_losses\"],\n",
    "        \"train_viol\": saved_train[\"train_viol\"],\n",
    "        \"val_viol\": saved_train[\"val_viol\"],\n",
    "        \"train_time\": saved_train[\"train_time\"],\n",
    "        \"best_epoch\": saved_train[\"best_epoch\"],\n",
    "        \"test_losses\": saved_test[\"test_loss\"],\n",
    "        \"test_viol\": saved_test[\"test_viol\"],\n",
    "        \"test_gini\": saved_test[\"test_gini\"],\n",
    "    })\n",
    "\n",
    "print(f\" Loaded {len(results)} models from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e646d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sort and pick best based on early stopping ---\n",
    "best_id = min(range(len(results)), key=lambda i: min(results[i][\"val_losses\"]))\n",
    "best_result = results[best_id]\n",
    "best_hyperparams = hyper_params[best_id]\n",
    "best_val_loss = min(best_result[\"val_losses\"])\n",
    "\n",
    "print(\"\\n Best config:\")\n",
    "print(\n",
    "    f\"   ED={best_hyperparams['embedding dim']}, \"\n",
    "    f\"M={best_hyperparams['margin']}\"\n",
    ")\n",
    "print(f\"   Best Validation Loss={best_val_loss:.4f}\")\n",
    "print(f\"   Training Time: {best_result['train_time']:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_i = [\"viol\",\"losses\",\"gini\"]\n",
    "embedding_exp = ['1/8', '1/4', '1/2', '1', '2', '4']\n",
    "hidden_exp = ['1/8', '1/4', '1/2', '1', '2', '4', '8', '16', '32']\n",
    "#metric = \"viol\"\n",
    "#metric = \"losses\"\n",
    "#metric = \"gini\"\n",
    "mouse_exp = 20*16*16\n",
    "human_exp = 300*16*16\n",
    "\n",
    "xvar = 'embedding dim'\n",
    "yvar = 'margin'\n",
    "xvals = sorted(set(r[xvar] for r in hyper_params))\n",
    "yvals = sorted(set(r[yvar] for r in hyper_params))\n",
    "\n",
    "# Define styles\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "yvals_to_color = {ed: colors[i % len(colors)] for i, ed in enumerate(yvals)}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 6))\n",
    "ip = 0\n",
    "for metric in metric_i:\n",
    "    \n",
    "    \n",
    "    xval_array = np.array(xvals)\n",
    "\n",
    "    for yval in yvals:\n",
    "        ip += 1\n",
    "        plt.subplot(3,2,ip)\n",
    "\n",
    "        test_losses = []\n",
    "        for xval in xvals:\n",
    "            model_id = next(i for i, r in enumerate(hyper_params)\n",
    "                            if r[xvar] == xval and r[yvar] == yval)\n",
    "\n",
    "            test_losses.append(results[model_id]['test_'+metric])\n",
    "\n",
    "        color = yvals_to_color[yval]\n",
    "        label = f\"{yvar}={yval}\"\n",
    "        plt.plot(xval_array, test_losses, 'o-',label=label,alpha=0.5)\n",
    "        yl = plt.ylim()  # get current y-axis limits\n",
    "        plt.plot(mouse_exp*np.ones(2), yl, '--r', linewidth=2)  # vertical line at x=3\n",
    "        #plt.plot(human_exp*np.ones(2), yl, '-.g', linewidth=2)  # vertical line at x=7\n",
    "        # Formatting\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(xvar)\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(label)\n",
    "        #plt.legend()\n",
    "        plt.tight_layout()\n",
    "plt.savefig('figures/test_results_margin_1_4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c040a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values\n",
    "hds = sorted(set(r['margin'] for r in hyper_params))\n",
    "eds = sorted(set(r['embedding dim'] for r in hyper_params))\n",
    "\n",
    "n_hds = len(hds)\n",
    "n_eds = len(eds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hd_array = np.array(hds)\n",
    "ed_array = np.array(eds)\n",
    "\n",
    "test_loss = np.zeros((n_eds,n_hds))\n",
    "test_viol = np.zeros((n_eds,n_hds))\n",
    "test_gini = np.zeros((n_eds,n_hds))\n",
    "best_epoch = np.zeros((n_eds,n_hds),dtype=int)\n",
    "train_time = np.zeros((n_eds,n_hds))\n",
    "for ied,ed in enumerate(eds):\n",
    "    \n",
    "    val_losses = []\n",
    "    for ihd,hd in enumerate(hds):\n",
    "        model_id = next(i for i, r in enumerate(hyper_params)\n",
    "                        if r['embedding dim'] == ed and \n",
    "                        r['margin'] == hd)\n",
    "\n",
    "        test_loss[ied,ihd] = results[model_id]['test_losses']\n",
    "        test_viol[ied,ihd] = results[model_id]['test_viol']\n",
    "        test_gini[ied,ihd] = results[model_id]['test_gini']\n",
    "        best_epoch[ied,ihd] = results[model_id]['best_epoch']\n",
    "        train_time[ied,ihd] = results[model_id]['train_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce901b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_blocks_fixed(blocks, p, q):\n",
    "    m, n1, n2 = blocks.shape\n",
    "    assert n1 == n2, \"Blocks must be square\"\n",
    "    assert m == p * q, \"m must equal p * q\"\n",
    "    n = n1\n",
    "    reshaped = blocks.reshape(p, q, n, n)\n",
    "    merged = reshaped.swapaxes(1, 2).reshape(p * n, q * n)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resmooth_weights(model, sigma=0.25):\n",
    "    weight = model.fc.weight.data\n",
    "    emb_dim = weight.shape[0]\n",
    "    weight_reshaped = weight.view(emb_dim, 1, 16, 16)\n",
    "\n",
    "    kernel_size = int(2 * round(3 * sigma) + 1)\n",
    "    kernel = gaussian_kernel2d(kernel_size, sigma, device=weight.device)\n",
    "    kernel = kernel.view(1, 1, kernel_size, kernel_size)\n",
    "\n",
    "    smoothed = F.conv2d(weight_reshaped, kernel, padding=kernel_size // 2)\n",
    "    model.fc.weight.data.copy_(smoothed.view(emb_dim, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d689d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(16*16, embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        out = self.relu(self.fc(x))  # Linear followed by ReLU\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel2d(kernel_size=5, sigma=0.25, device='cpu'):\n",
    "    ax = torch.arange(kernel_size, device=device) - kernel_size // 2\n",
    "    xx, yy = torch.meshgrid(ax, ax, indexing=\"xy\")\n",
    "    kernel = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    kernel /= kernel.sum()\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ab847",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load best model\n",
    "weights_reshaped = []\n",
    "for model_id in range(n_models):\n",
    "\n",
    "    ed = hyper_params[model_id][\"embedding dim\"]\n",
    "\n",
    "    margin = hyper_params[model_id][\"margin\"]\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    model_file = f\"models/linear_M{margin_str}_ED{ed}_EP{epochs}.pt\"\n",
    "    model = EmbeddingNet(embedding_dim=ed)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # ---- Smooth the weights again ----\n",
    "    resmooth_weights(model, sigma=1.)\n",
    "\n",
    "    # Extract weights from first layer (input to hidden): shape (n_hidden_units, 256)\n",
    "    first_layer = model.fc  # Replace if you used a different name\n",
    "    weights = first_layer.weight.detach().cpu().numpy()  # shape: (n_hidden_units, 256)\n",
    "\n",
    "    # Reshape to (n_hidden_units, 16, 16)\n",
    "    weights_reshaped.append(weights.reshape(weights.shape[0], 16, 16))\n",
    "\n",
    "    #print(\"Weight shape:\", weights_reshaped[model_id].shape)  # (n_hidden_units, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 16\n",
    "p = 4 # rows \n",
    "q = 8 # columns\n",
    "size_factor = 0.5\n",
    "for model_id in range(n_models):\n",
    "    \n",
    "    embedding_dim = hyper_params[model_id]['embedding dim']\n",
    "    margin = hyper_params[model_id]['margin']\n",
    "    # ---- Filter ----\n",
    "    if margin != 4.0 or embedding_dim not in [32, 512, 4096]:\n",
    "        continue  # skip models that don't match criteria\n",
    "    \n",
    "    merged_rf = rearrange_blocks_fixed(weights_reshaped[model_id][:32,:,:], p=p, q=q)\n",
    "    plt.figure(figsize=(q*size_factor,p*size_factor))\n",
    "    plt.imshow(merged_rf)\n",
    "    for i in range(q+1):\n",
    "        plt.plot(i*n*np.ones(2)-0.5,np.array([0,n*p])-0.5,'w')\n",
    "    for i in range(p+1):\n",
    "        plt.plot(np.array([0,n*q])-0.5,i*n*np.ones(2)-0.5,'w')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    embedding_dim = hyper_params[model_id]['embedding dim']\n",
    "    margin = hyper_params[model_id]['margin']\n",
    "    #lambda_str = \"0\" if l1_lambda == 0 else f\"{l1_lambda:.0e}\".replace('-', 'm')\n",
    "    plt.title(f\"M={margin}, ED={embedding_dim}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/RF_ED{embedding_dim}.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
