{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40855784-cf70-4126-b37c-cc86ad91726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.manifold._t_sne\")\n",
    "\n",
    "import time\n",
    "\n",
    "import itertools\n",
    "#import torch\n",
    "#from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split, Dataset\n",
    "#from torch.utils.data import DataLoader\n",
    "#import numpy as np\n",
    "#import itertools\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfed4927-1af3-439c-a382-72f28f1c4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/sakinkirti/Programming/ucla/dipoppa-lab/01_data/digits/\"\n",
    "model_path = \"/Users/sakinkirti/Programming/ucla/dipoppa-lab/01_data/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddf5f92-8b27-4269-9e04-d4dbbebcbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file path and variable name (adjust as needed)\n",
    "data_name = \"triplet_digits_2\"\n",
    "mat_path = file_path + data_name + \".mat\"\n",
    "#mat_path = file_path + \"allPatches.mat\"\n",
    "#mat_key = \"allPatches\"\n",
    "mat_key = \"triplets\"\n",
    "mat_lab = \"labels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3ebace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw MAT shape: (16, 16, 3, 100000)\n",
      "(16, 16, 3, 100000)\n",
      "Triplet_data shape: torch.Size([100000, 3, 16, 16])\n",
      "Labels: (1, 100000)\n"
     ]
    }
   ],
   "source": [
    "v7 = 1\n",
    "\n",
    "if v7 == 1:\n",
    "    # --- Load from MATLAB v7 (non-HDF5) ---\n",
    "    mat = loadmat(mat_path)  # mat_path is your .mat file\n",
    "    raw = mat[mat_key]       # mat_key is the variable name inside the .mat file\n",
    "    print(\"Raw MAT shape:\", raw.shape)\n",
    "    data = raw  # no transpose if shape is already correct\n",
    "    \n",
    "    labels = mat[\"labels\"]\n",
    "else:\n",
    "    # Load from HDF5\n",
    "    with h5py.File(mat_path, 'r') as f:\n",
    "        raw = f[mat_key]\n",
    "        print(\"Raw HDF5 shape:\", raw.shape)\n",
    "        data = np.array(raw)  # this ensures a clean ndarray\n",
    "        \n",
    "print(data.shape)\n",
    "\n",
    "# Transpose\n",
    "data = data.transpose(3, 2, 0, 1)\n",
    "    \n",
    "# --- Convert to float32 Torch tensor ---\n",
    "triplet_data = torch.tensor(data).float() / 255.0\n",
    "\n",
    "# Compute dataset mean & std once:\n",
    "mean = triplet_data.mean()\n",
    "std = triplet_data.std()\n",
    "\n",
    "# Normalize entire dataset:\n",
    "triplet_data = (triplet_data - mean) / std\n",
    "\n",
    "print(\"Triplet_data shape:\", triplet_data.shape)\n",
    "print(\"Labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "075a23cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba249475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ii in range(3):\n",
    "    plt.subplot(1,3,ii+1)\n",
    "    plt.imshow(triplet_data[0,ii,:,:].detach().cpu().numpy())\n",
    "    if ii == 0:\n",
    "        plt.title(labels[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64ac857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Margin Stats:\n",
      "  Mean anchor-positive distance: 21.6915\n",
      "  Mean anchor-negative distance: 22.1980\n",
      "  % Triplets violating margin (4.0): 69.74%\n"
     ]
    }
   ],
   "source": [
    "# Extract anchor, positive, and negative from the triplet tensor\n",
    "anchor   = triplet_data[:, 0, :, :]\n",
    "positive = triplet_data[:, 1, :, :]\n",
    "negative = triplet_data[:, 2, :, :]\n",
    "\n",
    "# Flatten images into vectors\n",
    "a = anchor.reshape(anchor.size(0), -1)\n",
    "p = positive.reshape(positive.size(0), -1)\n",
    "n = negative.reshape(negative.size(0), -1)\n",
    "\n",
    "# Compute distances\n",
    "ap_dist = F.pairwise_distance(a, p)\n",
    "an_dist = F.pairwise_distance(a, n)\n",
    "\n",
    "# Compute margin violations\n",
    "margin = 4.\n",
    "violations = (ap_dist + margin > an_dist).float()\n",
    "\n",
    "# Compute stats\n",
    "mean_ap = ap_dist.mean().item()\n",
    "mean_an = an_dist.mean().item()\n",
    "violation_rate = violations.mean().item()\n",
    "\n",
    "# Print results\n",
    "print(\"Triplet Margin Stats:\")\n",
    "print(f\"  Mean anchor-positive distance: {mean_ap:.4f}\")\n",
    "print(f\"  Mean anchor-negative distance: {mean_an:.4f}\")\n",
    "print(f\"  % Triplets violating margin ({margin}): {violation_rate * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc9cac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Logistic Regression Accuracy: 0.5020\n",
      "üìà ROC AUC Score: 0.5015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Assume triplet_data is a tensor of shape (N, 3, H, W)\n",
    "# Convert to numpy if needed\n",
    "X_np = triplet_data.numpy() if isinstance(triplet_data, torch.Tensor) else triplet_data\n",
    "\n",
    "# Extract positives and negatives\n",
    "positives = X_np[:, 1].reshape(X_np.shape[0], -1)  # shape: (N, H*W)\n",
    "negatives = X_np[:, 2].reshape(X_np.shape[0], -1)\n",
    "\n",
    "# Stack data and labels\n",
    "X = np.vstack([positives, negatives])  # shape: (2N, H*W)\n",
    "y = np.hstack([np.ones(len(positives)), np.zeros(len(negatives))])  # shape: (2N,)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "print(f\"üîç Logistic Regression Accuracy: {acc:.4f}\")\n",
    "print(f\"üìà ROC AUC Score: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "672de0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(x):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    if np.amin(x) < 0:\n",
    "        raise ValueError(\"Gini index is only defined for non-negative values\")\n",
    "    if np.all(x == 0):\n",
    "        return 0.0  # Convention: Gini is 0 for uniform zero vector\n",
    "\n",
    "    x_sorted = np.sort(x)\n",
    "    n = len(x)\n",
    "    index = np.arange(1, n + 1)\n",
    "    return (2 * np.sum(index * x_sorted) / np.sum(x)) / n - (n + 1) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7513448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_triplet_margin_stats(model, dataloader, device, margin=0.2):\n",
    "\n",
    "    model.eval()\n",
    "    ap_dists = []\n",
    "    an_dists = []\n",
    "    violations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for a, p, n in dataloader:\n",
    "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "\n",
    "            anchor = model(a)\n",
    "            positive = model(p)\n",
    "            negative = model(n)\n",
    "\n",
    "            ap = F.pairwise_distance(anchor, positive)\n",
    "            an = F.pairwise_distance(anchor, negative)\n",
    "\n",
    "            ap_dists.append(ap)\n",
    "            an_dists.append(an)\n",
    "            violations.append((ap + margin > an).float())\n",
    "\n",
    "    ap_dists = torch.cat(ap_dists)\n",
    "    an_dists = torch.cat(an_dists)\n",
    "    violations = torch.cat(violations)\n",
    "\n",
    "    mean_ap = ap_dists.mean().item()\n",
    "    mean_an = an_dists.mean().item()\n",
    "    violation_rate = violations.mean().item()\n",
    "\n",
    "    return mean_ap, mean_an, violation_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7befba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data import Dataset\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, triplet_tensor):\n",
    "        self.triplets = triplet_tensor  # could be a Tensor or a Subset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        triplet = self.triplets[idx]\n",
    "        anchor = triplet[0].unsqueeze(0)  # shape: (1, 16, 16)\n",
    "        positive = triplet[1].unsqueeze(0)\n",
    "        negative = triplet[2].unsqueeze(0)\n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ca09d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Example dataset with data and labels ----\n",
    "# triplet_data: Tensor of shape [N, 3, 16, 16]\n",
    "# labels:       Numpy array of length N (integer labels)\n",
    "N = len(triplet_data)\n",
    "labels = np.array(labels[0,:])  # Make sure you have labels aligned with triplet_data\n",
    "\n",
    "# ---- Create random permutation of indices ----\n",
    "indices = torch.randperm(N)\n",
    "train_size = int(0.7 * N)\n",
    "val_size = int(0.1 * N)\n",
    "test_size = N - train_size - val_size\n",
    "\n",
    "train_idx = indices[:train_size]\n",
    "val_idx = indices[train_size:train_size + val_size]\n",
    "test_idx = indices[train_size + val_size:]\n",
    "\n",
    "# ---- Split dataset ----\n",
    "train_data = Subset(triplet_data, train_idx)\n",
    "val_data = Subset(triplet_data, val_idx)\n",
    "test_data = Subset(triplet_data, test_idx)\n",
    "\n",
    "# ---- Save label splits ----\n",
    "train_labels = labels[train_idx.numpy()]\n",
    "val_labels = labels[val_idx.numpy()]\n",
    "test_labels = labels[test_idx.numpy()]\n",
    "\n",
    "# ---- Create DataLoaders ----\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(TripletDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TripletDataset(val_data), batch_size=batch_size)\n",
    "test_loader = DataLoader(TripletDataset(test_data), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23f614db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(16*16, embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        out = self.relu(self.fc(x))  # Linear followed by ReLU\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d3eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, data_loader, criterion, device, l1_lambda=0.0):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_triplet = 0.0\n",
    "    total_l1 = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for a, p, n in data_loader:\n",
    "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "            a_out, p_out, n_out = model(a), model(p), model(n)\n",
    "\n",
    "            triplet_loss = criterion(a_out, p_out, n_out)\n",
    "\n",
    "            l1_penalty = 0.0\n",
    "            if l1_lambda > 0:\n",
    "                l1_penalty = (\n",
    "                    a_out.abs().sum() +\n",
    "                    p_out.abs().sum() +\n",
    "                    n_out.abs().sum()\n",
    "                ) / a_out.shape[0]\n",
    "\n",
    "            loss = triplet_loss + l1_lambda * l1_penalty\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_triplet += triplet_loss.item()\n",
    "            total_l1 += l1_penalty\n",
    "\n",
    "    n_batches = len(data_loader)\n",
    "    return (\n",
    "        total_loss / n_batches,\n",
    "        total_triplet / n_batches,\n",
    "        total_l1 / n_batches\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25491a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel2d(kernel_size=5, sigma=0.25, device='cpu'):\n",
    "    ax = torch.arange(kernel_size, device=device) - kernel_size // 2\n",
    "    xx, yy = torch.meshgrid(ax, ax, indexing=\"xy\")\n",
    "    kernel = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    kernel /= kernel.sum()\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84af563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_weights(model, sigma=0.25):\n",
    "    # Get weights and reshape (embedding_dim, 256) -> (embedding_dim, 1, 16, 16)\n",
    "    weight = model.fc.weight.data\n",
    "    emb_dim = weight.shape[0]\n",
    "    weight_reshaped = weight.view(emb_dim, 1, 16, 16)\n",
    "\n",
    "    # Build Gaussian kernel\n",
    "    kernel_size = int(2 * round(3 * sigma) + 1)\n",
    "    kernel = gaussian_kernel2d(kernel_size, sigma, device=weight.device)\n",
    "    kernel = kernel.view(1, 1, kernel_size, kernel_size)\n",
    "\n",
    "    # Convolve all embeddings in one pass (treat each as separate batch)\n",
    "    smoothed = F.conv2d(weight_reshaped, kernel, padding=kernel_size // 2)\n",
    "\n",
    "    # Flatten back and copy into model\n",
    "    model.fc.weight.data.copy_(smoothed.view(emb_dim, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "130d8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, device, data_name,\n",
    "          embedding_dim, epochs=10, patience=5, min_delta=1e-4, l1_lambda=0.0,\n",
    "         margin=0.2):\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    train_triplet_losses, val_triplet_losses = [], []\n",
    "    train_l1_norms, val_l1_norms = [], []\n",
    "    \n",
    "    train_violations, val_violations = [], []\n",
    "    \n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    best_epoch = 0\n",
    "    wait = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ---- Initial evaluation before training ----\n",
    "    train_loss, train_triplet_loss, train_l1_norm = evaluate_loss(model, train_loader,\n",
    "                                                            criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_triplet_losses.append(train_triplet_loss)\n",
    "    train_l1_norms.append(train_l1_norm)\n",
    "    \n",
    "    _, _, v_train = compute_triplet_margin_stats(model, train_loader, device)\n",
    "    train_violations.append(v_train)\n",
    "\n",
    "    val_loss, val_triplet_loss, val_l1_norm = evaluate_loss(model, val_loader,\n",
    "                                                            criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_triplet_losses.append(val_triplet_loss)\n",
    "    val_l1_norms.append(val_l1_norm)\n",
    "    \n",
    "    _, _, v_val = compute_triplet_margin_stats(model, val_loader, device)\n",
    "    val_violations.append(v_val)\n",
    "\n",
    "    best_val_loss = val_losses[-1]\n",
    "    best_state = model.state_dict()\n",
    "\n",
    "    # ---- Training loop ----\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_triplet = 0.0\n",
    "        total_l1 = 0.0\n",
    "        \n",
    "        for a, p, n in train_loader:\n",
    "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "            a_out, p_out, n_out = model(a), model(p), model(n)\n",
    "            triplet_loss = criterion(a_out, p_out, n_out)\n",
    "\n",
    "            l1_penalty = 0.0\n",
    "            if l1_lambda > 0:\n",
    "                l1_penalty = (\n",
    "                    a_out.abs().sum() +\n",
    "                    p_out.abs().sum() +\n",
    "                    n_out.abs().sum()\n",
    "                ) / a_out.shape[0]\n",
    "\n",
    "            loss = triplet_loss + l1_lambda * l1_penalty\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_triplet += triplet_loss.item()\n",
    "            total_l1 += l1_penalty\n",
    "\n",
    "        \n",
    "            \n",
    "        train_losses.append(total_loss / len(train_loader))\n",
    "        train_triplet_losses.append(total_triplet / len(train_loader))\n",
    "        train_l1_norms.append(total_l1 / len(train_loader))\n",
    "        \n",
    "        smooth_weights(model, sigma=0.25)\n",
    "        \n",
    "        # compute violations\n",
    "        _, _, v_train = compute_triplet_margin_stats(model, train_loader, device)\n",
    "        train_violations.append(v_train)\n",
    "\n",
    "        val_loss, val_triplet_loss, val_l1_norm = evaluate_loss(model, val_loader, criterion, device, l1_lambda)\n",
    "        val_losses.append(val_loss)\n",
    "        val_triplet_losses.append(val_triplet_loss)\n",
    "        val_l1_norms.append(val_l1_norm)\n",
    "        _, _, v_val = compute_triplet_margin_stats(model, val_loader, device)\n",
    "        val_violations.append(v_val)\n",
    "\n",
    "        if val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"\\n‚èπÔ∏è Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        print('.', end='', flush=True)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f' Epoch {epoch + 1}')\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "\n",
    "        \n",
    "    # Save model state separately\n",
    "    #lambda_str = \"0\" if l1_lambda == 0 else f\"{l1_lambda:.0e}\".replace('-', 'm')\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    model_path = f\"{model_path}/class_{data_name}_M{margin_str}_ED{embedding_dim}_EP{epochs}.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Save metadata separately\n",
    "    meta_path = f\"{model_path}/class_{data_name}_M{margin_str}_ED{embedding_dim}_EP{epochs}.pkl\"\n",
    "    with open(meta_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"train_triplet_losses\": train_triplet_losses,\n",
    "            \"val_triplet_losses\": val_triplet_losses,\n",
    "            \"train_l1_norms\": train_l1_norms,\n",
    "            \"val_l1_norms\": val_l1_norms,\n",
    "            \"train_viol\": train_violations,\n",
    "            \"val_viol\": val_violations,\n",
    "            \"train_time\": total_time,\n",
    "            \"best_epoch\": best_epoch\n",
    "        }, f)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d41160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Fixed hyperparameters\n",
    "epochs = 300\n",
    "patience = 5\n",
    "min_delta = 1e-4\n",
    "\n",
    "# --- Hyperparameter grid ---\n",
    "learning_rate = [1e-4]\n",
    "weight_decays = [0]\n",
    "batch_sizes = [64]\n",
    "\n",
    "l1_lambdas = [0]\n",
    "# embedding_dims = [8, 16, 32, 64, 128, 256, 512]\n",
    "# margins = [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "embedding_dims = [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
    "margins = [3., 4., 5.]\n",
    "\n",
    "hyper_params = []\n",
    "model_id = 0\n",
    "\n",
    "\n",
    "for lr, wd, bs, ed, ll, mm in itertools.product(learning_rate, weight_decays, batch_sizes,\\\n",
    "                                            embedding_dims, l1_lambdas, margins):\n",
    "    hyper_params.append({\n",
    "        \"model id\": model_id,\n",
    "        \"learning rate\": lr,\n",
    "        \"weight decay\": wd,\n",
    "        \"batch size\": bs,\n",
    "        \"embedding dim\": ed,\n",
    "        \"l1 lambda\": ll,\n",
    "        \"margin\": mm,\n",
    "        \"epochs\": epochs,\n",
    "        \"patience\": patience,\n",
    "        \"min delta\": min_delta,\n",
    "    })\n",
    "\n",
    "    \n",
    "n_models = len(hyper_params)\n",
    "print(n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b1ffe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in range(n_models):\n",
    "    lr = hyper_params[model_id][\"learning rate\"]\n",
    "    wd = hyper_params[model_id][\"weight decay\"]\n",
    "    bs = hyper_params[model_id][\"batch size\"]\n",
    "    ed = hyper_params[model_id][\"embedding dim\"]\n",
    "    ll = hyper_params[model_id][\"l1 lambda\"]\n",
    "    epochs = hyper_params[model_id][\"epochs\"]\n",
    "    margin = hyper_params[model_id][\"margin\"]\n",
    "    patience = hyper_params[model_id][\"patience\"]\n",
    "    min_delta = hyper_params[model_id][\"min delta\"]\n",
    "    #lambda_str = \"0\" if ll == 0 else f\"{ll:.0e}\".replace('-', 'm')\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    hyper_path = f\"{model_path}/class_{data_name}_hyper_M{margin_str}_ED{ed}_EP{epochs}.pkl\"\n",
    "    with open(hyper_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "        \"model id\": model_id,\n",
    "        \"learning rate\": lr,\n",
    "        \"weight decay\": wd,\n",
    "        \"batch size\": bs,\n",
    "        \"embedding dim\": ed,\n",
    "        \"l1 lambda\": ll,\n",
    "        \"epochs\": epochs,\n",
    "        \"margin\": margin,\n",
    "        \"patience\": patience,\n",
    "        \"min delta\": min_delta,\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e884e039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 1/30 with M=3.0, ED=32, WD=0, BS=64\n",
      ".......... Epoch 10\n",
      ".......... Epoch 20\n",
      ".......... Epoch 30\n",
      "..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wd)\n\u001b[32m     24\u001b[39m     criterion = nn.TripletMarginLoss(margin=margin)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     model = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m                    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43med\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[43mll\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmargin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmargin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGrid completed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, criterion, device, data_name, embedding_dim, epochs, patience, min_delta, l1_lambda, margin)\u001b[39m\n\u001b[32m     78\u001b[39m smooth_weights(model, sigma=\u001b[32m0.25\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# compute violations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m _, _, v_train = \u001b[43mcompute_triplet_margin_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m train_violations.append(v_train)\n\u001b[32m     84\u001b[39m val_loss, val_triplet_loss, val_l1_norm = evaluate_loss(model, val_loader, criterion, device, l1_lambda)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mcompute_triplet_margin_stats\u001b[39m\u001b[34m(model, dataloader, device, margin)\u001b[39m\n\u001b[32m     12\u001b[39m anchor = model(a)\n\u001b[32m     13\u001b[39m positive = model(p)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m negative = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m ap = F.pairwise_distance(anchor, positive)\n\u001b[32m     17\u001b[39m an = F.pairwise_distance(anchor, negative)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/tce_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/tce_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mEmbeddingNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m      8\u001b[39m     x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Flatten\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Linear followed by ReLU\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/tce_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/tce_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1743\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1739\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n\u001b[32m   1741\u001b[39m \u001b[38;5;66;03m# torchrec tests the code consistency with the following code\u001b[39;00m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1744\u001b[39m     forward_call = (\u001b[38;5;28mself\u001b[39m._slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch._C._get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward)\n\u001b[32m   1745\u001b[39m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Iterate over all combinations ---\n",
    "for model_id in range(n_models):\n",
    "    learning_rate = hyper_params[model_id][\"learning rate\"]\n",
    "    wd = hyper_params[model_id][\"weight decay\"]\n",
    "    bs = hyper_params[model_id][\"batch size\"]\n",
    "    ed = hyper_params[model_id][\"embedding dim\"]\n",
    "    ll = hyper_params[model_id][\"l1 lambda\"]\n",
    "    epochs = hyper_params[model_id][\"epochs\"]\n",
    "    margin = hyper_params[model_id][\"margin\"]\n",
    "    patience = hyper_params[model_id][\"patience\"]\n",
    "    min_delta = hyper_params[model_id][\"min delta\"]\n",
    "    \n",
    "    #lambda_str = \"0\" if ll == 0 else f\"{ll:.0e}\".replace('-', 'm')\n",
    "    #margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    print(f\"\\nTraining {model_id+1}/{n_models} with M={margin}, ED={ed}, WD={wd}, BS={bs}\")\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(TripletDataset(train_data), batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(TripletDataset(val_data), batch_size=bs)\n",
    "\n",
    "    model = EmbeddingNet(embedding_dim=ed)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wd)\n",
    "    criterion = nn.TripletMarginLoss(margin=margin)\n",
    "\n",
    "    model = train(model,train_loader,val_loader,\n",
    "                    optimizer,criterion,device,\n",
    "                    data_name, embedding_dim=ed, epochs=epochs,patience=patience,\n",
    "                      min_delta=min_delta, l1_lambda=ll,margin=margin)\n",
    "\n",
    "print(f\"Grid completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e56d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for hp in hyper_params:  # assuming hyper_params is a list of dicts with 'hidden dim' and 'embedding dim'\n",
    "    embedding_dim = hp['embedding dim']\n",
    "    margin = hp['margin']\n",
    "    #lambda_str = \"0\" if l1_lambda == 0 else f\"{l1_lambda:.0e}\".replace('-', 'm')\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    filename = f\"models/class_{data_name}_M{margin_str}_ED{embedding_dim}_EP{epochs}.pkl\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"‚ö†Ô∏è File not found: {filename}\")\n",
    "        continue\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        print(filename)\n",
    "        saved = pickle.load(f)\n",
    "\n",
    "    results.append({\n",
    "        \"train_losses\": saved[\"train_losses\"],\n",
    "        \"val_losses\": saved[\"val_losses\"],\n",
    "        \"train_viol\": saved[\"train_viol\"],\n",
    "        \"val_viol\": saved[\"val_viol\"],\n",
    "        \"train_time\": saved[\"train_time\"],\n",
    "        \"best_epoch\": saved[\"best_epoch\"],        \n",
    "    })\n",
    "\n",
    "print(f\" Loaded {len(results)} models from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98255fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Get all unique margins ---\n",
    "margins = sorted(set(hp[\"margin\"] for hp in hyper_params))\n",
    "\n",
    "best_m_id = []\n",
    "\n",
    "print(\"\\n Best model for each margin:\")\n",
    "for m in margins:\n",
    "    # All models with this margin\n",
    "    margin_ids = [i for i, hp in enumerate(hyper_params) if hp[\"margin\"] == m]\n",
    "    \n",
    "    # Pick the one with minimum validation loss\n",
    "    best_id = min(margin_ids, key=lambda i: min(results[i][\"val_losses\"]))\n",
    "    best_m_id.append(best_id)\n",
    "    \n",
    "    # Print summary for this margin\n",
    "    best_loss = min(results[best_id][\"val_losses\"])\n",
    "    ed = hyper_params[best_id]['embedding dim']\n",
    "    print(f\"Margin={m}: Model ID={best_id}, ED={ed}, Best Validation Loss={best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sort and pick best based on early stopping ---\n",
    "best_id = min(range(len(results)), key=lambda i: min(results[i][\"val_losses\"]))\n",
    "best_result = results[best_id]\n",
    "best_hyperparams = hyper_params[best_id]\n",
    "best_val_loss = min(best_result[\"val_losses\"])\n",
    "best_val_viol = min(best_result[\"val_viol\"])\n",
    "\n",
    "print(\"\\n Best config:\")\n",
    "print(f\"   ED={best_hyperparams['embedding dim']}, \"\n",
    "    f\"M={best_hyperparams['margin']}\")\n",
    "print(f\"   Best Validation Loss={best_val_loss:.4f}\")\n",
    "print(f\"   Training Time: {best_result['train_time']:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b80cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_output_activations(model, model_file, test_loader, device):\n",
    "\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    out_acts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for anchor, positive, negative in test_loader:\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            out_anchor = model(anchor)\n",
    "            out_positive = model(positive)\n",
    "            out_negative = model(negative)\n",
    "\n",
    "            out_batch = torch.stack([out_anchor, out_positive, out_negative], dim=1)\n",
    "            out_acts.append(out_batch.cpu())\n",
    "\n",
    "    out_acts = torch.cat(out_acts, dim=0).numpy()\n",
    "    return out_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98caf4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 20000\n",
    "test_results = []\n",
    "emb_act = []\n",
    "for model_id in range(n_models):\n",
    "    ed = hyper_params[model_id][\"embedding dim\"]\n",
    "    margin = hyper_params[model_id][\"margin\"]\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    model_file = f\"models/class_{data_name}_M{margin_str}_ED{ed}_EP{epochs}.pt\"\n",
    "    print(f\"M{margin_str}, ED{ed}, EP{epochs}\")\n",
    "    if not os.path.exists(model_file):\n",
    "        print(f\" Missing files for ED={ed}\")\n",
    "        continue\n",
    "\n",
    "    model = EmbeddingNet(embedding_dim=ed)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    criterion = nn.TripletMarginLoss(margin=margin)\n",
    "    # --- Compute test loss using evaluate_loss ---\n",
    "    test_loss, test_triplet_loss, test_l1_norm = evaluate_loss(model, test_loader,\n",
    "                                                                  criterion, device)\n",
    "\n",
    "    # --- Compute margin violation percentage on test set ---\n",
    "    _, _, test_violation_pct = compute_triplet_margin_stats(model, test_loader,\n",
    "                                                            device, margin=0.2)\n",
    "\n",
    "    # Compute Gini index\n",
    "    out_acts = extract_output_activations(model=model,model_file=model_file,\n",
    "        test_loader=test_loader,device=device)\n",
    "    #print(\"Hidden activations shape:\", out_acts.shape)\n",
    "    emb_act.append(out_acts[:,0,:])\n",
    "    gini_act = np.zeros((n_test,3))\n",
    "    for i in range(n_test):\n",
    "        for j in range(3):\n",
    "            gini_act[i,j] = gini_index(out_acts[i,j,:])\n",
    "    gini_act_m = np.mean(gini_act)\n",
    "    \n",
    "    test_results.append({\n",
    "        \"test_losses\": test_loss,\n",
    "        \"test_triplet_loss\": test_triplet_loss,\n",
    "        \"test_l1_norm\": test_l1_norm,\n",
    "        \"test_viol\": test_violation_pct,\n",
    "        \"test_gini\": gini_act_m,\n",
    "    })\n",
    "    \n",
    "    test_path = f\"models/class_test_{data_name}_M{margin_str}_ED{ed}_EP{epochs}.pkl\"\n",
    "    with open(test_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_triplet_loss\": test_triplet_loss,\n",
    "        \"test_l1_norm\": test_l1_norm,\n",
    "        \"test_viol\": test_violation_pct,\n",
    "        \"test_gini\": gini_act_m,\n",
    "        }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_param(val):\n",
    "    if val == 0:\n",
    "        return \"0\"\n",
    "    elif val < 1:\n",
    "        return f\"{val:.0e}\"\n",
    "    else:\n",
    "        return str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(result['best_epoch']  for result in results))\n",
    "print(max(result['best_epoch']  for result in results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"losses\"\n",
    "metric = \"viol\"\n",
    "\n",
    "min_loss = min(min(r[\"train_\"+metric] + r[\"val_\"+metric]) for r in results)\n",
    "max_loss = max(max(r[\"train_\"+metric] + r[\"val_\"+metric]) for r in results)\n",
    "\n",
    "xvar = 'embedding dim'\n",
    "yvar = 'margin'\n",
    "xvar2 = 'ED'\n",
    "yvar2 = 'M'\n",
    "xvals = sorted(set(r[xvar] for r in hyper_params))\n",
    "yvals = sorted(set(r[yvar] for r in hyper_params))\n",
    "nx = len(xvals)\n",
    "ny = len(yvals)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(nx*2,ny*2))\n",
    "ip = 0\n",
    "\n",
    "for yval in yvals:\n",
    "    \n",
    "\n",
    "    #ed = hyper_params[model_id][\"embedding dim\"]\n",
    "    for xval in xvals:\n",
    "\n",
    "        ip += 1\n",
    "        plt.subplot(ny,nx,ip)\n",
    "        \n",
    "        #xval = hyper_params[model_id][\"margin\"]\n",
    "        model_id = next(i for i, r in enumerate(hyper_params)\n",
    "                            if r[xvar] == xval and r[yvar] == yval)\n",
    "\n",
    "\n",
    "        hyper_p = f\"{yvar2}={yval}, {xvar2}={xval}\"\n",
    "\n",
    "        best_id = best_m_id[yvals.index(yval)]\n",
    "        plt.plot(results[best_id]['train_'+metric],'k--',alpha=0.5)\n",
    "        plt.plot(results[best_id]['val_'+metric],'k-',alpha=0.5)\n",
    "        plt.plot(results[best_id]['best_epoch'],test_results[best_id]['test_'+metric],'ko',alpha=0.5)\n",
    "\n",
    "        plt.plot(results[model_id]['train_'+metric],'b--')\n",
    "        plt.plot(results[model_id]['val_'+metric],'b-')\n",
    "        plt.plot(results[model_id]['best_epoch'],test_results[model_id]['test_'+metric],'bo')\n",
    "        plt.ylim(min_loss,max_loss)\n",
    "        plt.title(hyper_p)\n",
    "        #plt.yscale('log')\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda2cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_i = [\"viol\",\"losses\",\"gini\"]\n",
    "#metric = \"viol\"\n",
    "#metric = \"losses\"\n",
    "#metric = \"gini\"\n",
    "mouse_exp = 20*16*16\n",
    "human_exp = 300*16*16\n",
    "\n",
    "xvar = 'embedding dim'\n",
    "yvar = 'margin'\n",
    "xvals = sorted(set(r[xvar] for r in hyper_params))\n",
    "yvals = sorted(set(r[yvar] for r in hyper_params))\n",
    "\n",
    "# Define styles\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "yvals_to_color = {ed: colors[i % len(colors)] for i, ed in enumerate(yvals)}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ip = 0\n",
    "for metric in metric_i:\n",
    "    \n",
    "    \n",
    "    xval_array = np.array(xvals)\n",
    "\n",
    "    for yval in [2.0]:\n",
    "        ip += 1\n",
    "        plt.subplot(3,5,ip)\n",
    "\n",
    "        test_losses = []\n",
    "        for xval in xvals:\n",
    "            model_id = next(i for i, r in enumerate(hyper_params)\n",
    "                            if r[xvar] == xval and r[yvar] == yval)\n",
    "\n",
    "            test_losses.append(test_results[model_id]['test_'+metric])\n",
    "        print(min(test_losses))\n",
    "        color = yvals_to_color[yval]\n",
    "        label = f\"{yvar}={yval}\"\n",
    "        plt.plot(xval_array, test_losses, 'o-',label=label,alpha=0.5)\n",
    "        yl = plt.ylim()  # get current y-axis limits\n",
    "        #plt.plot(mouse_exp*np.ones(2), yl, '--r', linewidth=2)  # vertical line at x=3\n",
    "        #plt.plot(human_exp*np.ones(2), yl, '-.g', linewidth=2)  # vertical line at x=7\n",
    "        # Formatting\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Embedding dimension\")\n",
    "        if metric == \"viol\":\n",
    "            plt.ylabel(\"Fraction violations\")\n",
    "        elif metric == \"losses\":\n",
    "            plt.ylabel(\"Triplet loss\")\n",
    "        elif metric == \"gini\":\n",
    "            plt.ylabel(\"Gini index\")\n",
    "\n",
    "        \n",
    "        #plt.title(label)\n",
    "        #plt.legend()\n",
    "        plt.tight_layout()\n",
    "plt.savefig('figures/test_results_margin4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_i = [\"viol\",\"losses\",\"gini\"]\n",
    "#metric = \"viol\"\n",
    "#metric = \"losses\"\n",
    "#metric = \"gini\"\n",
    "mouse_exp = 20*16*16\n",
    "human_exp = 300*16*16\n",
    "\n",
    "xvar = 'embedding dim'\n",
    "yvar = 'margin'\n",
    "xvals = sorted(set(r[xvar] for r in hyper_params))\n",
    "yvals = sorted(set(r[yvar] for r in hyper_params))\n",
    "nx = len(xvals)\n",
    "ny = len(yvals)\n",
    "nm = len(metric_i)\n",
    "\n",
    "# Define styles\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "yvals_to_color = {ed: colors[i % len(colors)] for i, ed in enumerate(yvals)}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(ny*2, nm*2))\n",
    "ip = 0\n",
    "for metric in metric_i:\n",
    "    \n",
    "    \n",
    "    xval_array = np.array(xvals)\n",
    "\n",
    "    for yval in yvals:\n",
    "        ip += 1\n",
    "        plt.subplot(nm,ny,ip)\n",
    "\n",
    "        test_losses = []\n",
    "        for xval in xvals:\n",
    "            model_id = next(i for i, r in enumerate(hyper_params)\n",
    "                            if r[xvar] == xval and r[yvar] == yval)\n",
    "\n",
    "            test_losses.append(test_results[model_id]['test_'+metric])\n",
    "\n",
    "        color = yvals_to_color[yval]\n",
    "        label = f\"{yvar}={yval}\"\n",
    "        plt.plot(xval_array, test_losses, 'o-',label=label,alpha=0.5)\n",
    "        yl = plt.ylim()  # get current y-axis limits\n",
    "        #plt.plot(mouse_exp*np.ones(2), yl, '--r', linewidth=2)  # vertical line at x=3\n",
    "        \n",
    "        # Formatting\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(xvar)\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(label)\n",
    "        #plt.legend()\n",
    "        plt.tight_layout()\n",
    "plt.savefig(f'figures/test_results_{data_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea97edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_blocks_fixed(blocks, p, q):\n",
    "    m, n1, n2 = blocks.shape\n",
    "    assert n1 == n2, \"Blocks must be square\"\n",
    "    assert m == p * q, \"m must equal p * q\"\n",
    "    n = n1\n",
    "    reshaped = blocks.reshape(p, q, n, n)\n",
    "    merged = reshaped.swapaxes(1, 2).reshape(p * n, q * n)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resmooth_weights(model, sigma=0.25):\n",
    "    weight = model.fc.weight.data\n",
    "    emb_dim = weight.shape[0]\n",
    "    weight_reshaped = weight.view(emb_dim, 1, 16, 16)\n",
    "\n",
    "    kernel_size = int(2 * round(3 * sigma) + 1)\n",
    "    kernel = gaussian_kernel2d(kernel_size, sigma, device=weight.device)\n",
    "    kernel = kernel.view(1, 1, kernel_size, kernel_size)\n",
    "\n",
    "    smoothed = F.conv2d(weight_reshaped, kernel, padding=kernel_size // 2)\n",
    "    model.fc.weight.data.copy_(smoothed.view(emb_dim, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de3918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "weights_reshaped = []\n",
    "for model_id in range(n_models):\n",
    "\n",
    "    ed = hyper_params[model_id][\"embedding dim\"]\n",
    "\n",
    "    margin = hyper_params[model_id][\"margin\"]\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    model_file = f\"models/class_{data_name}_M{margin_str}_ED{ed}_EP{epochs}.pt\"\n",
    "    model = EmbeddingNet(embedding_dim=ed)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # ---- Smooth the weights again ----\n",
    "    resmooth_weights(model, sigma=.5)\n",
    "\n",
    "    # Extract weights from first layer (input to hidden): shape (n_hidden_units, 256)\n",
    "    first_layer = model.fc  # Replace if you used a different name\n",
    "    weights = first_layer.weight.detach().cpu().numpy()  # shape: (n_hidden_units, 256)\n",
    "\n",
    "    # Reshape to (n_hidden_units, 16, 16)\n",
    "    weights_reshaped.append(weights.reshape(weights.shape[0], 16, 16))\n",
    "\n",
    "    #print(\"Weight shape:\", weights_reshaped[model_id].shape)  # (n_hidden_units, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = 16\n",
    "p = 4 # rows \n",
    "q = 8 # columns\n",
    "size_factor = 1.\n",
    "for model_id in range(n_models):\n",
    "    \n",
    "    embedding_dim = hyper_params[model_id]['embedding dim']\n",
    "    margin = hyper_params[model_id]['margin']\n",
    "    # ---- Filter ----\n",
    "    if margin != 3.0 or embedding_dim not in [32, 1024]:\n",
    "        continue  # skip models that don't match criteria\n",
    "    \n",
    "    merged_rf = rearrange_blocks_fixed(weights_reshaped[model_id][:32,:,:], p=p, q=q)\n",
    "    plt.figure(figsize=(q*size_factor,p*size_factor))\n",
    "    plt.imshow(merged_rf)\n",
    "    for i in range(q+1):\n",
    "        plt.plot(i*n*np.ones(2)-0.5,np.array([0,n*p])-0.5,'w')\n",
    "    for i in range(p+1):\n",
    "        plt.plot(np.array([0,n*q])-0.5,i*n*np.ones(2)-0.5,'w')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    embedding_dim = hyper_params[model_id]['embedding dim']\n",
    "    margin = hyper_params[model_id]['margin']\n",
    "    #lambda_str = \"0\" if l1_lambda == 0 else f\"{l1_lambda:.0e}\".replace('-', 'm')\n",
    "    plt.title(f\"{data_name}, M={margin}, ED={embedding_dim}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    margin_str = f\"{margin:.1f}\".replace('.', 'p')\n",
    "    plt.savefig(f'figures/RF_class_{data_name}_M{margin_str}_ED{embedding_dim}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 3.\n",
    "ed = 1024\n",
    "\n",
    "model_id = next(i for i, r in enumerate(hyper_params)\n",
    "                if r[\"embedding dim\"] == ed and\n",
    "                r[\"margin\"] == margin)\n",
    "print(model_id)\n",
    "print(emb_act[model_id].shape)\n",
    "\n",
    "ed = 32\n",
    "model_id_32 = next(i for i, r in enumerate(hyper_params)\n",
    "                if r[\"embedding dim\"] == ed and\n",
    "                r[\"margin\"] == margin)\n",
    "print(model_id_32)\n",
    "print(emb_act[model_id_32].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8989479",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(triplet_data[indices, 0, :, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b116b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract anchors (only channel 0)\n",
    "anchors = triplet_data[indices, 0, :, :]  # shape: (20000, 16, 16)\n",
    "\n",
    "# Flatten to 20000 x 256 safely\n",
    "anchors_flat = anchors.reshape(anchors.size(0), -1)  # or use .contiguous().view(...)\n",
    "\n",
    "# Convert to NumPy\n",
    "anchors_np = anchors_flat.numpy()\n",
    "print(\"Shape:\", anchors_np.shape)  # (20000, 256)\n",
    "\n",
    "np.save(f'models/anchors_data_{data_name}.npy',anchors_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7554205",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = hyper_params[model_id][\"epochs\"]\n",
    "np.savez(f\"models/emb_act_data_{data_name}_EP{epochs}.npz\", **{f\"arr_{i}\": arr for i, arr in enumerate(emb_act)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98071f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(f'models/test_labels_{data_name}.npy',test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit PCA ---\n",
    "pca0 = PCA(n_components=2)  # 2D projection\n",
    "pca0.fit(anchors_np)  # shape: (20000, 2)\n",
    "anchors_pca = pca0.transform(anchors_np)  # shape: (20000, 2)\n",
    "\n",
    "# --- Explained variance ---\n",
    "print(\"Explained variance ratio:\", pca0.explained_variance_ratio_)\n",
    "print(\"Total variance explained:\", pca0.explained_variance_ratio_.sum())\n",
    "\n",
    "\n",
    "# --- Fit PCA ---\n",
    "pca32 = PCA(n_components=2)  # 2D projection\n",
    "pca32.fit(emb_act[model_id_32])  # shape: (20000, 2)\n",
    "emb_pca32 = pca32.transform(emb_act[model_id_32])  # shape: (20000, 2)\n",
    "\n",
    "# --- Explained variance ---\n",
    "print(\"Explained variance ratio:\", pca32.explained_variance_ratio_)\n",
    "print(\"Total variance explained:\", pca32.explained_variance_ratio_.sum())\n",
    "\n",
    "# --- Fit PCA ---\n",
    "pca = PCA(n_components=2)  # 2D projection\n",
    "pca.fit(emb_act[model_id])  # shape: (20000, 2)\n",
    "emb_pca = pca.transform(emb_act[model_id])  # shape: (20000, 2)\n",
    "\n",
    "# --- Explained variance ---\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total variance explained:\", pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1,3,1)\n",
    "scatter = plt.scatter(anchors_pca[:, 0], anchors_pca[:, 1], \n",
    "                      c=test_labels, cmap=\"tab10\", s=2)\n",
    "#plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.title(\"PCA, 256 input dimensions\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "scatter = plt.scatter(emb_pca32[:, 0], emb_pca32[:, 1], \n",
    "                      c=test_labels, cmap=\"tab10\", s=2)\n",
    "#plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.title(\"PCA, 32 embedding dimensions\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "scatter = plt.scatter(emb_pca[:, 0], emb_pca[:, 1], \n",
    "                      c=test_labels, cmap=\"tab10\", s=2)\n",
    "#plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.title(\"PCA, 1024 embedding dimensions\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'figures/PCA_{data_name}_M{margin_str}_ED{ed}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dfaaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_indices(n_samples, val_size=0.2, test_size=0.2, random_state=42):\n",
    "    # First split train+val and test\n",
    "    train_val_idx, test_idx = train_test_split(np.arange(n_samples),\n",
    "                                               test_size=test_size,\n",
    "                                               random_state=random_state,\n",
    "                                               shuffle=True)\n",
    "    # Split train and val\n",
    "    train_idx, val_idx = train_test_split(train_val_idx,\n",
    "                                          test_size=val_size/(1-test_size),\n",
    "                                          random_state=random_state,\n",
    "                                          shuffle=True)\n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "# Example usage:\n",
    "N = len(labels)  # number of samples\n",
    "train_idx, val_idx, test_idx = create_split_indices(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f81612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_softmax_classifier_pre_split(X_train, y_train, X_val, y_val,\n",
    "                                       lr=1e-3, weight_decay=1e-3,\n",
    "                                       epochs=2000, patience=20):\n",
    "    \"\"\"\n",
    "    Train a linear softmax classifier using pre-split data.\n",
    "    \"\"\"\n",
    "    # ---- Ensure tensors and correct dtypes ----\n",
    "    if not isinstance(X_train, torch.Tensor):\n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    else:\n",
    "        X_train = X_train.float()\n",
    "\n",
    "    if not isinstance(X_val, torch.Tensor):\n",
    "        X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "    else:\n",
    "        X_val = X_val.float()\n",
    "\n",
    "    if not isinstance(y_train, torch.Tensor):\n",
    "        y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    else:\n",
    "        y_train = y_train.long()\n",
    "\n",
    "    if not isinstance(y_val, torch.Tensor):\n",
    "        y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "    else:\n",
    "        y_val = y_val.long()\n",
    "\n",
    "    # ---- Model, Loss, Optimizer ----\n",
    "    model = LinearSoftmax(X_train.shape[1], len(torch.unique(y_train)))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # ---- Tracking ----\n",
    "    history = {\n",
    "        \"val_loss\": [], \"val_acc\": [],\n",
    "        \"train_loss\": [], \"train_acc\": []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Train ---\n",
    "        model.train()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss = loss.item()\n",
    "        train_pred = outputs.argmax(dim=1)\n",
    "        train_acc = (train_pred == y_train).float().mean().item()\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss = criterion(val_outputs, y_val).item()\n",
    "            val_pred = val_outputs.argmax(dim=1)\n",
    "            val_acc = (val_pred == y_val).float().mean().item()\n",
    "\n",
    "        # ---- Store metrics ----\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        # --- Early stopping ---\n",
    "        if val_loss < best_val_loss - 1e-5:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a58bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSoftmax(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # softmax handled by loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca50d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Compute test loss and accuracy for a trained model.\n",
    "    \"\"\"\n",
    "    # Ensure correct tensor types\n",
    "    if not isinstance(X_test, torch.Tensor):\n",
    "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    else:\n",
    "        X_test = X_test.float()\n",
    "\n",
    "    if not isinstance(y_test, torch.Tensor):\n",
    "        y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "    else:\n",
    "        y_test = y_test.long()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        loss = criterion(outputs, y_test).item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        acc = (preds == y_test).float().mean().item()\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8110ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X1 = torch.tensor(anchors_np, dtype=torch.float32)  # shape: (20000, 256)\n",
    "X2a = torch.tensor(emb_act[model_id_32], dtype=torch.float32)  # shape: (20000, 1024)\n",
    "X2 = torch.tensor(emb_act[model_id], dtype=torch.float32)  # shape: (20000, 1024)\n",
    "y = torch.tensor(test_labels, dtype=torch.long)         # shape: (20000,)\n",
    "\n",
    "train_idx, val_idx, test_idx = create_split_indices(n_samples=20000, val_size=0.2,\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "X1_train, X1_val, X1_test = X1[train_idx], X1[val_idx], X1[test_idx]\n",
    "X2a_train, X2a_val, X2a_test = X2a[train_idx], X2a[val_idx], X2a[test_idx]\n",
    "X2_train, X2_val, X2_test = X2[train_idx], X2[val_idx], X2[test_idx]\n",
    "y_train, y_val, y_test = y[train_idx], y[val_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98babf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose A and B are PyTorch tensors or datasets\n",
    "len_A, len_B = 12000, 4000\n",
    "\n",
    "# Index vectors for A and B\n",
    "indices_A = torch.arange(len_A)\n",
    "indices_B = torch.arange(len_B)\n",
    "\n",
    "sizes_A = [120,1200,12000]\n",
    "sizes_B = [40,400,4000]\n",
    "\n",
    "model1_i = []\n",
    "model2a_i = []\n",
    "model2_i = []\n",
    "\n",
    "for size_A, size_B in zip(sizes_A, sizes_B):\n",
    "    idx_A = indices_A[:size_A]  # take first size_A samples of A\n",
    "    idx_B = indices_B[:size_B]  # take first size_B samples of B\n",
    "    \n",
    "    # Train on one dataset (e.g., X1)\n",
    "    model1, history1 = train_softmax_classifier_pre_split(X1_train[idx_A], y_train[idx_A],\n",
    "                                                          X1_val[idx_B], y_val[idx_B])\n",
    "    model1_i.append(model1)\n",
    "    print()\n",
    "    \n",
    "    # Train on another dataset (e.g., X2)\n",
    "    model2a, history2 = train_softmax_classifier_pre_split(X2a_train[idx_A], y_train[idx_A],\n",
    "                                                          X2a_val[idx_B], y_val[idx_B])\n",
    "    model2a_i.append(model2a)\n",
    "    print()\n",
    "    \n",
    "    # Train on another dataset (e.g., X2)\n",
    "    model2, history2 = train_softmax_classifier_pre_split(X2_train[idx_A], y_train[idx_A],\n",
    "                                                          X2_val[idx_B], y_val[idx_B])\n",
    "    model2_i.append(model2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c91752",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc1_i = []\n",
    "test_acc2a_i = []\n",
    "test_acc2_i = []\n",
    "for i in range(3):\n",
    "    test_loss1, test_acc1 = evaluate_model(model1_i[i], X1_test, y_test)\n",
    "    print(f\"Dataset X1 - Test Loss: {test_loss1:.4f}, Test Accuracy: {test_acc1:.4f}\")\n",
    "    test_acc1_i.append(test_acc1)\n",
    "    # Train on another dataset (e.g., X2)\n",
    "    test_loss2a, test_acc2a = evaluate_model(model2a_i[i], X2a_test, y_test)\n",
    "    print(f\"Dataset X2 - Test Loss: {test_loss2a:.4f}, Test Accuracy: {test_acc2a:.4f}\")\n",
    "    test_acc2a_i.append(test_acc2a)\n",
    "    \n",
    "    test_loss2, test_acc2 = evaluate_model(model2_i[i], X2_test, y_test)\n",
    "    print(f\"Dataset X2 - Test Loss: {test_loss2:.4f}, Test Accuracy: {test_acc2:.4f}\")\n",
    "    test_acc2_i.append(test_acc2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = [160,1600,16000]\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.plot(num_samples,test_acc1_i,'o-',label='inputs')\n",
    "plt.plot(num_samples,test_acc2a_i,'o-',label='embeddings (32)')\n",
    "plt.plot(num_samples,test_acc2_i,'o-',label='embeddings (1024)')\n",
    "plt.plot(num_samples,np.ones(3),'k--')\n",
    "plt.plot(num_samples,0.1*np.ones(3),'k--')\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Test accuracy\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figures/test_accuracy_{data_name}_M{margin_str}_ED{ed}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cda55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tce_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
